{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "데이터 불러오기부터\n",
    "가. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d86868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d75124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나. 데이터 불러오기\n",
    "df_feature = pd.read_csv(\"onenavi_train_feature.csv\",sep=\"|\")\n",
    "df_target = pd.read_csv(\"onenavi_train_target.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7dc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "나. Train/Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_feature, df_target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "모델 최적화 : Hyperparameter Tuning\n",
    "Hyperparmeter는 머신러닝에서 모델을 학습하기 전에 설정해주는 옵션 값이라고 할 수 있습니다.\n",
    "설정을 머신러닝이 스스로 찾을 수 있다면 참 좋을텐데\n",
    "불가능하기 때문에 우리가 직접 찾아서 설정 해주어야 합니다.\n",
    "모델을 최적화하는 전략은 크게 Panda전략과 Caviar전략으로 나누어볼 수 있는데요.\n",
    "간단하게 두 전략의 개념을 짚어보고 실습하는 시간을 가지겠습니다.\n",
    "지금부터 모델 최적화를 시작합니다.\n",
    "1. Panda전략 : Babysitting one model\n",
    "크게 하나의 모델을 정하고 성능을 평가하면서 점진적으로 모델을 '돌보기'하는 전략\n",
    "한 번에 한마리씩 아기를 가지는 팬더는 아기 팬더가 살아남을 수 있도록 지극정성으로 케어를 하는데, 여기서도 동일하게 하나의 모델을 잘 케어해서 최적화하는 개념을 이야기한다.Image\n",
    "[Panda 전략 Tip : XGBoost 기준]\n",
    "\n",
    "모델 성능을 높이고 싶다면!\n",
    "n-estimators는 높게, eta는 낮게\n",
    "튜닝 예시\n",
    "n-estimators와 learning_rate를 먼저 지정(n-estimators를 100으로 고정하고 최적 learning_rate 찾기)\n",
    "나머지 hyperparameter 튜닝\n",
    "n-estimators와 learning_rate 조정(둘은 반비례, 꼭 법칙은 아님!)\n",
    "(예시) n-estimators를 2배 늘리면 learning_rate는 1/2로, n-estimators를 10배 늘리면 learning_rate는 1/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f622901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 n-estimators와 learning_rate(eta)를 먼저 지정 : eta 0.1 => R-squared Score on Test set : 0.71631\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "model=xgb(n_estimators=100, eta=0.1)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "print(\"RMSE on Test set : {0:.5f}\".format(mean_squared_error(test_y,pred_y)**0.5))\n",
    "print(\"R-squared Score on Test set : {0:.5f}\".format(r2_score(test_y,pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 n-estimators와 learning_rate(eta)를 먼저 지정 : eta 0.2 => R-squared Score on Test set : 0.71680\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "model=xgb(n_estimators=100, eta=0.2)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "print(\"RMSE on Test set : {0:.5f}\".format(mean_squared_error(test_y,pred_y)**0.5))\n",
    "print(\"R-squared Score on Test set : {0:.5f}\".format(r2_score(test_y,pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계 n-estimators와 learning_rate(eta)를 먼저 지정 : eta 0.3 => R-squared Score on Test set : 0.70988\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "model=xgb(n_estimators=100, eta=0.3)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "print(\"RMSE on Test set : {0:.5f}\".format(mean_squared_error(test_y,pred_y)**0.5))\n",
    "print(\"R-squared Score on Test set : {0:.5f}\".format(r2_score(test_y,pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계 나머지 hyperparameter 튜닝 : 0.71724\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "model=xgb(n_estimators=100, eta=0.2, \n",
    "          max_depth=5, subsample= 0.8, colsample_bytree=0.5, reg_alpha=3, gamma=5)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "print(\"RMSE on Test set : {0:.5f}\".format(mean_squared_error(test_y,pred_y)**0.5))\n",
    "print(\"R-squared Score on Test set : {0:.5f}\".format(r2_score(test_y,pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계 n-estimators와 learning_rate 조정 : 0.71890\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "model=xgb(n_estimators=200, eta=0.1,\n",
    "          max_depth=5, subsample= 0.8, colsample_bytree=0.5, reg_alpha=3, gamma=5)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "pred_y = model.predict(test_x)\n",
    "print(\"RMSE on Test set : {0:.5f}\".format(mean_squared_error(test_y,pred_y)**0.5))\n",
    "print(\"R-squared Score on Test set : {0:.5f}\".format(r2_score(test_y,pred_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 저장합니다.\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(model, '4_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2. Caviar전략 : Training many models in parallel\n",
    "여러개 모델을 동시에 돌려서 가장 좋은 모델을 선택하는 전략\n",
    "한 철에 1억개의 알을 품는 물고기가 있다고 한다. 물고기가 번식하는 과정은 하나에 많은 집중을 쏟기보다 하나 또는 그 이상이 더 잘 살아남기를 그지 지켜보는데, 여기에서 착안하여 여러 모델을 시도해서 최적의 모델을 찾는 전략을 Caviar전략이라고 한다. image.png\n",
    "Caviar 전략에서는 Tip이라고 정리하기보다 Gridsearch라는 유용한 라이브러리를 소개하고자 한다.\n",
    "Gridsearch는 여러 모델을 코드 몇 줄로 시도하고 최적 파라미터를 도출하기에 편하다.\n",
    "다만, 시간이 많이 걸린다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ead526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "params = { 'n_estimators' : [50, 100, 200],\n",
    "           'learning_rate' : [0, 0.01],\n",
    "           'max_depth' : [0, 3],\n",
    "            }\n",
    "\n",
    "xgb_model = xgb(random_state = 0, n_jobs = 1)\n",
    "grid_cv = GridSearchCV(xgb_model, param_grid = params, cv = 3, n_jobs = 1)\n",
    "start_time = time.process_time()\n",
    "grid_cv.fit(train_x, train_y)\n",
    "end_time = time.process_time()\n",
    "\n",
    "print('----  {0:.5f}sec, training complete  ----'.format(end_time-start_time))\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as lr\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as grb\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.read_csv(\"onenavi_evaluation_new.csv\",sep=\"|\")\n",
    "df_evaluation_feature = pd.read_csv(\"onenavi_eval_feature.csv\",sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b97d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rslt = []\n",
    "for i in range(5):\n",
    "    model_rslt.append(joblib.load(\"{}_model.pkl\".format(i)))\n",
    "model_rslt.append(keras.models.load_model(\"DeeplearningModel.h5\"))\n",
    "model_rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1_list = ['ETA1', 'ETA2', 'ETA3', 'ETA4', 'ETA5', 'ETA6']\n",
    "e2_list = ['ETAA1', 'ETAA2', 'ETAA3', 'ETAA4', 'ETAA5', 'ETAA6']\n",
    "\n",
    "for e1, e2, model in zip(e1_list, e2_list, model_rslt):\n",
    "    df_evaluation[e1] = model.predict(df_evaluation_feature)\n",
    "    df_evaluation.loc[(df_evaluation[e1] < 0), e1] = 0\n",
    "    etaa = (1-(abs(df_evaluation['ET']-df_evaluation[e1])/df_evaluation['ET']))*100.0\n",
    "    df_evaluation[e2] = etaa\n",
    "    df_evaluation.loc[(df_evaluation[e2] < 0), e2] = 0\n",
    "\n",
    "# mean, min, max, std\n",
    "etaa = ['ETAA', 'ETAA1', 'ETAA2', 'ETAA3', 'ETAA4', 'ETAA5', 'ETAA6']\n",
    "alg = ['DATA', 'ML-LG', 'ML-RFR', 'ML-GBR', 'XBR', 'XBR2', 'Deep']\n",
    "\n",
    "print('+-------------------------------------------------------+')\n",
    "print('|   ALG    | Mean(%) |    STD    |  MIN(%)  |  MAX(%)   |')\n",
    "print('+----------+---------+-----------+----------+-----------+')\n",
    "for i, e in zip(range(len(alg)), etaa):\n",
    "    eMean = df_evaluation[e].mean()\n",
    "    eStd = df_evaluation[e].std()\n",
    "    eMin = df_evaluation[e].min()\n",
    "    eMax = df_evaluation[e].max()\n",
    "    print('|  {:6s}  |   {:3.1f}  |   {:05.1f}   |   {:4.1f}   |  {:7.1f}  |'.format(alg[i], eMean, eStd, eMin, eMax))\n",
    "print('+----------+---------+-----------+----------+-----------+\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "좀 더 상세한 분석을 위해 거리 구간별로 결과를 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "etaa = ['ETAA', 'ETAA1', 'ETAA2', 'ETAA3', 'ETAA4', 'ETAA5', 'ETAA6']\n",
    "alg = ['DATA', 'ML-LG', 'ML-RFR', 'ML-GBR', 'XBR', 'XBR2', 'Deep']\n",
    "\n",
    "for length in range(4):\n",
    "    if length == 0:\n",
    "        print(' 1,000 <= A_DISTANCE < 5,000m')\n",
    "    elif length == 1:\n",
    "        print(' 5,000 <= A_DISTANCE < 10,000m')\n",
    "    elif length == 2:\n",
    "        print(' 10,000 <= A_DISTANCE < 15,000m')\n",
    "    else:\n",
    "         print('All A_DISTANCE')\n",
    "    print('+-------------------------------------------------------+')\n",
    "    print('|   ALG    | Mean(%) |    STD    |  MIN(%)  |  MAX(%)   |')\n",
    "    print('+----------+---------+-----------+----------+-----------+')\n",
    "    for i, e in zip(range(len(alg)), etaa):\n",
    "        if length == 0:\n",
    "            eMean = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=1000) & (df_evaluation['A_DISTANCE']<5000), e].mean()\n",
    "            eStd = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=1000) & (df_evaluation['A_DISTANCE']<5000), e].std()\n",
    "            eMin = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=1000) & (df_evaluation['A_DISTANCE']<5000), e].min()\n",
    "            eMax = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=1000) & (df_evaluation['A_DISTANCE']<5000), e].max()\n",
    "        elif length == 1:\n",
    "            eMean = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=5000) & (df_evaluation['A_DISTANCE']<10000), e].mean()\n",
    "            eStd = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=5000) & (df_evaluation['A_DISTANCE']<10000), e].std()\n",
    "            eMin = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=5000) & (df_evaluation['A_DISTANCE']<10000), e].min()\n",
    "            eMax = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=5000) & (df_evaluation['A_DISTANCE']<10000), e].max()\n",
    "        elif length == 2:\n",
    "            eMean = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=10000) & (df_evaluation['A_DISTANCE']<15000), e].mean()\n",
    "            eStd = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=10000) & (df_evaluation['A_DISTANCE']<15000), e].std()\n",
    "            eMin = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=10000) & (df_evaluation['A_DISTANCE']<15000), e].min()\n",
    "            eMax = df_evaluation.loc[(df_evaluation['A_DISTANCE']>=10000) & (df_evaluation['A_DISTANCE']<15000), e].max()\n",
    "        else:\n",
    "            eMean = df_evaluation[e].mean()\n",
    "            eStd = df_evaluation[e].std()\n",
    "            eMin = df_evaluation[e].min()\n",
    "            eMax = df_evaluation[e].max()\n",
    "        print('|  {:6s}  |   {:3.1f}  |   {:05.1f}   |   {:4.1f}   |  {:7.1f}  |'.format(alg[i], eMean, eStd, eMin, eMax))\n",
    "    print('+----------+---------+-----------+----------+-----------+\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e54536",
   "metadata": {},
   "outputs": [],
   "source": [
    "모델의 R-squared Score, RMSE가 좋았다고해서 실제 평가데이터에 적용했을 때,\n",
    "비례해서 모델의 정확도 혹은 결과가 좋아지지 않는다는 사실을 알 수 있습니다.\n",
    "물론 두 수치가 좋아지면 모델의 정확도 혹은 결과가 좋아지는 경향은 있으나,\n",
    "정확하게 비례하지는 않습니다.\n",
    "그래서 다각도로 보면서 모델을 만들어줘야합니다.\n",
    "(과적합을 방지하고, 변수의 영향을 조정하는 등)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
