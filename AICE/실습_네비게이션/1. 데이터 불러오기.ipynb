{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec45ea94",
   "metadata": {},
   "source": [
    "안녕하세요^^\n",
    "AI 프로젝트 따라하기 - 원내비 도착시간 예측 모델링 과정에 오신 여러분을 환영합니다.\n",
    "본 과정에서는 주변에서 마주할 수 있는 연속성을 가지는 수치를 예측할 수 있는 회귀문제를 예제코드를 통해서 기계학습(머신러닝 및 딥러닝)을 활용해서 해결할 것입니다.\n",
    "네비게이션 주행데이터를 가지고 도착시간 정확도를 개선하는 과정을 통해 실전 AI 과제 수행에 있어 자신감을 가질 수 있는 기회가 되었으면 좋겠습니다.\n",
    "AI문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!\n",
    "기본전제\n",
    "[기본 데이터]\n",
    "\n",
    "학습데이터 : onenavi_train.csv(7월 20일에서 24일 사이의 수도권 3~15km 주행데이터)\n",
    "평가데이터 : onenavi_evaluation.csv(7월 27일에서 31일 사이의 수도권 3~15km 주행데이터)\n",
    "[추가 데이터]\n",
    "\n",
    "주소(시군구)데이터 : onenavi_pnu.csv(주행데이터를 기준으로 출발지의 주소 정보, key : RID)\n",
    "신호등(갯수)데이터 : onenavi_signal.csv(주행데이터를 기준으로 경로의 신호등 갯수, key : RID)\n",
    "날씨데이터 : onenavi_weather.csv(주행데이터를 기준으로 해당 일자의 수도권 날씨 정보, key : RID)\n",
    "1. 데이터 불러오기\n",
    "모든 AI프로젝트의 시작은 '데이터 불러오기' 부터라고 할 수 있습니다.\n",
    "KeyPoint : 불러오고자 하는 데이터에 따라 자유롭게 변수로 지정할 수 있다.\n",
    "[참고] AIDU에서는 반드시 추가 라이브러리 Import와 설정을 해야만 데이터 불러오기가 가능하다.\n",
    "※ 참고 : PEP8(https://www.python.org/dev/peps/pep-0008/)를 준수하나 교육상 필요 시 상황에 맞춰 실습할 예정입니다.\n",
    "    가. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ecd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daea829",
   "metadata": {},
   "outputs": [],
   "source": [
    "나. 데이터 프레임 변수로 저장(여기서는 CSV 기준으로 진행)\n",
    "csv : pd.read_csv(\"파일이름. csv\")\n",
    "txt : pd.read_csv(\"파일이름. csv\", sep=\"구분자\")\n",
    "xlsx : pd.read_excel('파일이름.xlsx')\n",
    "pickle : pd.read_pickle(\"파일이름.pkl\")\n",
    "[참고] pickle은 파이썬의 모든 객체를 파일로 저장할 수 있는 방법으로 DataFrame,List,Dict 등 모든 객체 저장 가능(특히 sklearn라이브러리를 통해 모델을 학습시키고, 저장할 때 많이 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cfd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"onenavi_train.csv\", sep=\"|\")\n",
    "df # 데이터 프레임 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeeef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "다. 학습데이터와 평가데이터 합치기\n",
    "학습데이터(onenavi_train.csv)는 7월 20일에서 24일까지 자료입니다.\n",
    "평가데이터(onenavi_evaluation.csv)는 7월 27일에서 31일까지 자료입니다.\n",
    "만약에 Train/Evaluation 데이터를 따로 전처리 한다면?\n",
    "전처리 기준(특히 정규화 작업 시)이 달라져서 모델의 성능에 악영향을 줄 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd55adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"onenavi_train.csv\",sep=\"|\")\n",
    "df_eval = pd.read_csv(\"onenavi_evaluation.csv\",sep=\"|\")\n",
    "# 학습/평가 데이터의 전처리 기준을 통일하기위해 데이터 합본\n",
    "df_total=pd.concat([df,df_eval],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c872580",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. 추가변수 생성\n",
    "주어진 데이터만 가지고 모델링을 한다면 세상을 너무 만만하게 보고 있는 것입니다.\n",
    "KeyPoint : 모델에 영향을 줄 수 있는 다양한 변수를 고민하고 기존 데이터와 Merge 할 수 있다.\n",
    "사실 추가변수 생성은 데이터 전처리 영역의 범위로 보는 경우도 있습니다.\n",
    "데이터 분석과 전처리는 '닭이 먼저냐? 달걀이 먼저냐?'와 같이 상호 인과관계를 가질 수 있습니다.\n",
    "다만 여기서는 교육의 원활한 진행을 위해 데이터 분석 이전에 진행하겠습니다.\n",
    "주행에 영향을 미치는 요소는 어떤 것이 있을까요? 저는 좌표정보와 경로의 신호등 여부를 생각해봤습니다.\n",
    "그렇다면 어떻게 변수화 할까요?\n",
    "좌표정보는 출발지의 좌표를 기준으로 시군구 단위를 주소정보로 신호등 여부는 경로 상의 신호등 갯수를 변수로 만들 수 있겠네요.\n",
    "Route ID를 기준으로 미리 데이터 프레임을 만들어 두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a5cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pnu = pd.read_csv(\"onenavi_pnu.csv\",sep=\"|\") # 주소(시도/시군구 정보)\n",
    "df_signal = pd.read_csv(\"onenavi_signal.csv\",sep=\"|\") # 경로의 신호등 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total=pd.merge(df_total,df_pnu , on=\"RID\")\n",
    "df_total=pd.merge(df_total,df_signal , on=\"RID\")\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. 데이터 분석하기\n",
    "최적의 모델을 만들기위해 데이터를 입체적으로 바라보는 시도는 중요합니다.\n",
    "KeyPoint : 데이터의 형태를 살펴보고 다양한 분석기법을 통해 모델링에 적합하도록 정제요소를 선별할 수 있다.\n",
    "관측치들의 패턴 탐색\n",
    "잘못된 자료들을 탐색\n",
    "변수들간의 관계 파악\n",
    "가. 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3135ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90719e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "나. Seaborn을 활용한 데이터 시각화\n",
    "Seaborn 라이브러리는 데이터를 직관적으로 볼 수 있도록 다양한 지원을 해주고 있습니다.\n",
    "여기서는 Seaborn이 제공하는 통계차트 중 대표적인 몇 가지를 활용해보고자 합니다.\n",
    "[참고] 공식 Document\n",
    "\n",
    "Seaborn(https://seaborn.pydata.org/api.html)\n",
    "Seaborn.CountChart(https://seaborn.pydata.org/generated/seaborn.countplot.html)\n",
    "Seaborn.Distplot(https://seaborn.pydata.org/generated/seaborn.distplot.html?highlight=distplot#seaborn.distplot) : 히스토그램 + 커널밀도\n",
    "Seaborn.Boxplot(https://seaborn.pydata.org/generated/seaborn.boxplot.html#seaborn.boxplot)\n",
    "Seaborn.Heatmap(https://seaborn.pydata.org/generated/seaborn.heatmap.html?highlight=heatmap#seaborn.heatmap)\n",
    "Seaborn.Pairplot(https://seaborn.pydata.org/generated/seaborn.pairplot.html?highlight=pairplot#seaborn.pairplot) : 조합별 히스토그램 + 산점도\n",
    "※ 데이터 분석 및 실습을 위해 Mock(Fake) 데이터를 활용하려고 합니다. 이를 위해 우리는 Faker 라이브러리를 사용하겠습니다.\n",
    "1) CountChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치된 폰트 리스트 출력\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fm.get_fontconfig_fonts()\n",
    "\n",
    "font_list = [font.name for font in fm.fontManager.ttflist]\n",
    "font_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font=\"NanumGothicCoding\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')\n",
    "ax = sns.countplot(x=df_total['level1_pnu'], palette = \"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdaa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) DistChart\n",
    "x = df_total['signaltype'] # 샘플 생성\n",
    "\n",
    "sns.distplot(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Boxplot\n",
    "# 만들어진 데이터프레임으로 BoxPlot을 그려보겠습니다.\n",
    "sns.boxplot(x = df_total['level1_pnu'], y = df_total['A_DISTANCE'], data = df_total, palette = \"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867af25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만들어진 데이터프레임으로 BoxPlot을 그려보겠습니다.\n",
    "sns.boxplot(x = df_total['level1_pnu'], y = df_total['ET'], data = df_total, palette = \"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Heatmap : 상관관계 분석 등에서 한 눈에 바로 확인할 수 있는 차트입니다.\n",
    "uniform_data = np.random.rand(10, 12) # 난수로 데이터 만들기\n",
    "sns.heatmap(uniform_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76734fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "5) Pariplot : 데이터 프레임의 수치형 변수를 기준으로 밀도와 분포를 한 눈에 확인할 수 있는 차트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347600f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "다. 상관관계 분석(Pandas/Seaborn)\n",
    "상관관계 분석은 왜 하는것일까요?\n",
    "막연하게 상관관계는 높으면 좋을 것 같습니다. 하지만 AI모델링을 할때 꼭 좋은 것은 아닙니다. 가령 살아온 날수와 식사를 한 끼니 수는 강한 상관관계를 가질 것입니다. 그러나 조금만 다르게 보면 둘은 같은 이야기를 하는 것이라고 할 수 있습니다.(다중공선성의 문제)\n",
    "상관관계 계수만으로 어떤 결정을 한다는 것은 섣부른 일입니다. 어떤 변수인지 확인이 반드시 필요하며, 시각화를 통해 분포도 확인하고 결정을 해야합니다.\n",
    "[다중공선성 해결 Tip]\n",
    "\n",
    "상관관계가 높은 독립변수중 하나 혹은 일부를 제거\n",
    "변수를 변형시키거나 새로운 관측치를 이용\n",
    "기타 다른 분석을 이용\n",
    "1) 상관계수 구하기 : Pandas는 Corr 함수를 통해 상관계수를 손쉽게 구하도록 도와줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Seaborn의 Heatmap을 활용한 시각화\n",
    "sns.heatmap(df_total.corr(), annot=True, cmap=\"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe4ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "라. [소개] 요인분석(FactorAnalyzer)\n",
    "다중공선성의 문제를 해결할 다른 방법은 무엇이 있을까? A: 변수를 변형시키거나 새로운 관측치를 이용\n",
    "요인분석이란 변수들 사이에서 잠재된 변수를 찾는 과정입니다. 이해를 위해 조금 거칠게 표현하면 드라마 선호도를 확인할 때 로멘스. 휴머니티, 범죄/스릴러, 정치, SF, 판타지 6가지로 조사한다면 내면에는 감성적(로맨스, 휴머니티), 이성적(범죄/스릴러, 정치), 창의적(SF, 판타지) 3가지 잠재적 요소의 영향을 확인하는 과정이라고 할 수 있습니다.\n",
    "요인분석을 통해 우리는 변수를 축소할 수 있고 잠재된 요소를 확인 할 수 있으나, 반드시 좋은 결과를 담보하는 것은 아니니 입체적으로 바라보고 적용해야 합니다.(일반적으로 크론바흐 계수 0.7이상에서 용인)\n",
    "1) 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78105467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FactorAnalyzer는 설치안된 경우가 많을 것입니다. 설치를 먼저 진행합니다.\n",
    "!pip install factor-analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfc731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2) Kaiser-Meyer-Olkin (KMO) 검정 : 요인 분석을위한 데이터의 적합성을 측정(0.6 미만의 KMO 값은 부적절한 것으로 간주)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cdf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요인분석은 수치형변수(int, float 등)으로만 이루어진 데이터에서 가능함으로 문자형 변수는 제거 필요\n",
    "df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmo_all,kmo_model=calculate_kmo(df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1))\n",
    "kmo_model # 0.642878086837649 : 0.6 이상으로 양호함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd608a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "3) ScreePlot을 활용한 요인수 결정 : Elbow 기법\n",
    "고유값(각각의 요인으로 설명할 수 있는 변수들의 분산 총합) 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요인분석 오브젝트를 만들고 실행해보겠습니다.\n",
    "fa = FactorAnalyzer()\n",
    "fa.set_params(rotation=None)\n",
    "fa.fit(df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1))\n",
    "# 고유값 확인 * 고유값(eigenvalue):각각의 요인으로 설명할 수 있는 변수들의 분산 총합\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784932a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree Plot을 그려서 Elbow 지점을 찾아봅시다.\n",
    "plt.scatter(range(1,df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1).shape[1]+1),ev)\n",
    "plt.plot(range(1,df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1).shape[1]+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13608b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) 요인부하량 확인 및 시각화\n",
    "# 요인분석 오브젝트를 만들고 실행해보겠습니다.\n",
    "fa = FactorAnalyzer()\n",
    "fa.set_params(n_factors=3, rotation=None)\n",
    "fa.fit(df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1))\n",
    "pd.DataFrame(fa.loadings_) # 요인부하량 확인 : 0.4이상 유의미, 0.5이상 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9c30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat Map으로 그려서 확인해보겠습니다.\n",
    "plt.figure(figsize=(6,10))\n",
    "sns.heatmap(fa.loadings_, cmap=\"Blues\", annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ab42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 크론바흐 계수(신뢰도) 계산 : 0.8이상 양호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크론바흐 계수를 계산하는 함수를 선언하겠습니다.\n",
    "def CronbachAlpha(itemscores):\n",
    "    itemscores = np.asarray(itemscores)\n",
    "    itemvars = itemscores.var(axis=0, ddof=1)\n",
    "    tscores = itemscores.sum(axis=1)\n",
    "    nitems = itemscores.shape[1]\n",
    "    return (nitems / (nitems-1)) * (1 - (itemvars.sum() / tscores.var(ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET와 ETA 신뢰계수\n",
    "print(CronbachAlpha(df[['ET','ETA']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bee491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET와 ETAA 신뢰계수\n",
    "print(CronbachAlpha(df[['ET','A_DISTANCE']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ec158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 요인점수를 활용한 변수 생성\n",
    "fa.transform(df.drop(['RID','TIME_DEPARTUREDATE','TIME_ARRIVEDATE'],axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
